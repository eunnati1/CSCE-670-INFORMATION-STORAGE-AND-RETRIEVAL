{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSCE 670 :: Information Storage and Retrieval :: Texas A&M University :: Spring 2020\n",
    "\n",
    "\n",
    "# Homework 2:  PageRank + Learning to Rank\n",
    "\n",
    "### 100 points [10% of your final grade]\n",
    "\n",
    "### Due: March 5, 2020 by 11:59pm\n",
    "\n",
    "*Goals of this homework:* In this homework you will explore real-world challenges of building a graph (in this case, from tweets), implement and test the classic PageRank algortihm over this graph. In addition, you will apply learning to rank to a real-world dataset and report the performance in terms of NDCG.\n",
    "\n",
    "*Submission instructions (eCampus):* To submit your homework, rename this notebook as `UIN_hw2.ipynb`. For example, my homework submission would be something like `555001234_hw2.ipynb`. Submit this notebook via eCampus (look for the homework 2 assignment there). Your notebook should be completely self-contained, with the results visible in the notebook. We should not have to run any code from the command line, nor should we have to run your code within the notebook (though we reserve the right to do so). So please run all the cells for us, and then submit.\n",
    "\n",
    "*Late submission policy:* For this homework, you may use as many late days as you like (up to the 5 total allotted to you).\n",
    "\n",
    "*Collaboration policy:* You are expected to complete each homework independently. Your solution should be written by you without the direct aid or help of anyone else. However, we believe that collaboration and team work are important for facilitating learning, so we encourage you to discuss problems and general problem approaches (but not actual solutions) with your classmates. You may post on Piazza, search StackOverflow, etc. But if you do get help in this way, you must inform us by **filling out the Collaboration Declarations at the bottom of this notebook**. \n",
    "\n",
    "*Example: I found helpful code on stackoverflow at https://stackoverflow.com/questions/11764539/writing-fizzbuzz that helped me solve Problem 2.*\n",
    "\n",
    "The basic rule is that no student should explicitly share a solution with another student (and thereby circumvent the basic learning process), but it is okay to share general approaches, directions, and so on. If you feel like you have an issue that needs clarification, feel free to contact either me or the TA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: PageRank (60 points)\n",
    "In this assignment, we're going to adapt the classic PageRank approach to allow us to find not the most authoritative web pages, but rather to find significant Twitter users. \n",
    "\n",
    "\n",
    "## Part 1.1: A re-Tweet Graph (20 points)\n",
    "\n",
    "So, instead of viewing the world as web pages with hyperlinks (where pages = nodes, hyperlinks = edges), we're going to construct a graph of Twitter users and their retweets of other Twitter users (so user = node, retweet of another user = edge). Over this Twitter-user graph, we can apply the PageRank approach to order the users. The main idea is that a user who is retweeted by other users is more \"impactful\". \n",
    "\n",
    "Here is a toy example. Suppose you are given the following four retweets:\n",
    "\n",
    "* **userID**: diane, **text**: \"RT \", **sourceID**: bob\n",
    "* **userID**: charlie, **text**: \"RT Welcome\", **sourceID**: alice\n",
    "* **userID**: bob, **text**: \"RT Hi \", **sourceID**: diane\n",
    "* **userID**: alice, **text**: \"RT Howdy!\", **sourceID**: parisa\n",
    "\n",
    "There are four short tweets retweeted by four users. The retweet between users form a directed graph with five nodes and four edges. E.g., the \"diane\" node has a directed edge to the \"bob\" node.\n",
    "\n",
    "You should build a graph by parsing the tweets in the file we provide called *PageRank.json*.\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "* You may see some weird characters in the content of tweets, just ignore them. \n",
    "* The edges are binary and directed. If Bob retweets Alice once, in 10 tweets, or 10 times in one tweet, there is an edge from Bob to Alice, but there is not an edge from Alice to Bob.\n",
    "* If a user retweets herself, ignore it.\n",
    "* Correctly parsing screen_name in a tweet is error-prone. Use the id of the user (this is the user who is re-tweeting) and the id of the user in the retweeted_status field (this is the user who is being re-tweeted; that is, this user created the original tweet).\n",
    "* Later you will need to implement the PageRank algorithm on the graph you build here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here define your function for building the graph by parsing \n",
    "# the input file of tweets\n",
    "# Insert as many cells as you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here define your function for building the graph \n",
    "# by parsing the input file \n",
    "# Insert as many cells as you want\n",
    "import numpy as np\n",
    "import json\n",
    "import itertools\n",
    "import operator\n",
    "import csv\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from statistics import mean "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FetchData(filename):\n",
    "    f = open(filename, encoding = \"utf8\")\n",
    "            \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build Graph Function to build a graph having tweet connections\n",
    "\n",
    "f = FetchData('HITS.json')\n",
    "\n",
    "def buildGraph():\n",
    "    twitterRelation = []\n",
    "    result = []\n",
    "    i =0\n",
    "    for item in f:\n",
    "        data = json.loads(item)\n",
    "        my_dict={}\n",
    "        my_dict['id']=data.get('user').get('id')\n",
    "        my_dict['retweeted user']=data.get('retweeted_status').get('user').get('id')\n",
    "        result.append(my_dict)\n",
    "        temp = [result[i].get('id'),result[i].get('retweeted user')]  \n",
    "        i += 1\n",
    "        twitterRelation.append(temp)\n",
    "\n",
    "    matrix = np.array(twitterRelation)\n",
    "    nodes = np.unique(matrix)\n",
    "    nodeindex = {n: i for i, n in enumerate(nodes)}\n",
    "    n = nodes.size\n",
    "    graph = np.zeros((n, n))\n",
    "    numdata = np.vectorize(nodeindex.get)(matrix)\n",
    "    check1 =[]\n",
    "    e=0 \n",
    "    ne =0\n",
    "    for t, h in numdata:\n",
    "        check = {\"tail\": t, \"head\": h}\n",
    "        if check in check1:\n",
    "            ne += 1\n",
    "        else:\n",
    "            check1.append(check)\n",
    "            e += 1\n",
    "      \n",
    "        graph[t, h] = 1\n",
    "     \n",
    "    return graph, n, e, nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph,n,edges, nodes = buildGraph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printSizeValues():\n",
    "    print(\"{} : {}\".format(\"Total number of nodes in the graph are\", n))\n",
    "    print(\"{} : {}\".format(\"Total number of edges in the graph are\", edges))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nodes in the graph are : 1003\n",
      "Total number of edges in the graph are : 6177\n"
     ]
    }
   ],
   "source": [
    "printSizeValues()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call your function to print out the size of the graph, \n",
    "# i.e., the number of nodes and edges\n",
    "# How you maintain the graph is totaly up to you\n",
    "# However, if you encounter any memory issues, we recommend you \n",
    "#write the graph into a file, and load it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will not check the correctness of your graph. However, this will affect the PageRank results later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.2: PageRank Implementation (30 points)\n",
    "\n",
    "Your program will return the top 10 users with highest PageRank scores. The **output** should be like:\n",
    "\n",
    "* user1 - score1\n",
    "* user2 - score2\n",
    "* ...\n",
    "* user10 - score10\n",
    "\n",
    "You should follow these **rules**:\n",
    "\n",
    "* Assume all nodes start out with equal probability.\n",
    "* The probability of the random surfer teleporting is 0.1 (that is, the damping factor is 0.9).\n",
    "* If a user is never retweeted and does not retweet anyone, their PageRank scores should be zero. Do not include the user in the calculation.\n",
    "* It is up to you to decide when to terminate the PageRank calculation.\n",
    "* There are PageRank implementations out there on the web. Remember, your code should be **your own**.\n",
    "\n",
    "\n",
    "**Hints**:\n",
    "* If you're using the matrix style approach, you should use [numpy.matrix](https://docs.scipy.org/doc/numpy/reference/generated/numpy.matrix.html).\n",
    "* Scipy is built on top of Numpy and has support for sparse matrices. You most likely will not need to use Scipy unless you'd like to try out their sparse matrices.\n",
    "* If you choose to use Numpy (and Scipy), please make sure your Anaconda environment include their latest versions.\n",
    "* Test your parsing and PageRank calculations using a handful of tweets, before moving on to the entire file we provide.\n",
    "* We will evaluate the user ranks you provide as well as the quality of your code. So make sure that your code is clear and readable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the termination condition in your PageRank implementation? Describe it below:\n",
    "\n",
    "*ADD YOUR ANSWER HERE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here add your code to implement a function called PageRanker\n",
    "# Insert as many cells as you want\n",
    "\n",
    "# def PageRanker(...):\n",
    "#    ...\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "def PageRanker(C,nodes, maxerr = .000001):\n",
    "    n = C.shape[0] #5\n",
    "    matrix = np.zeros((n, n))            \n",
    "    initial_value = 1 / n\n",
    "    ranks =np.ones((n,1)).dot(initial_value) # initial matrix(1003 x 1)   \n",
    "    n_iterations = 0\n",
    "    delta = 1.0\n",
    "    newRank= np.zeros((n,1))\n",
    "    for i in range(0,n):\n",
    "        matrix[i]=np.divide(C[i],sum(C[i]))\n",
    "        if np.any(np.isnan(matrix[i])) == True :\n",
    "            matrix[i]=np.add(C[i],(1/len(C[i])))\n",
    "                        \n",
    "    new_matrix = matrix.transpose()\n",
    "    teleport = np.ones((n,n))\n",
    "    H = new_matrix*(0.9) + teleport*((1-0.9)/n)\n",
    "       \n",
    "        \n",
    "    while delta > maxerr:\n",
    "        newRank = H.dot(ranks)\n",
    "       \n",
    "        n_iterations += 1\n",
    "        delta = sum(abs(newRank[node] - ranks[node]) for node in range(0,n))\n",
    "        ranks = newRank\n",
    "    \n",
    "    out=[]\n",
    "    for j in range(len(newRank)):\n",
    "        a = newRank[j]\n",
    "        out.append(a[0])\n",
    "    \n",
    "    \n",
    "    dicts = {}\n",
    "    keys = nodes\n",
    "    values = out\n",
    "    \n",
    "    for i in range(len(keys)):\n",
    "        dicts[keys[i]] = values[i]    \n",
    "    \n",
    "    \n",
    "    sorted_d = sorted(dicts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "   \n",
    "    return sorted_d[:10], n_iterations\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's call your function on the graph you've built. Output the results.\n",
    "pageranks, iterations  = PageRanker(graph,nodes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAGERANK OUTPUT:\n",
      "    PAGE          USER RANK\n",
      "(1183906148, 0.02842143948679257)\n",
      "(3019659587, 0.021570050798506712)\n",
      "(3077695572, 0.02093852100565467)\n",
      "(3068694151, 0.01850008734487332)\n",
      "(2598548166, 0.017636724442521616)\n",
      "(3154266823, 0.01738327797903532)\n",
      "(571198546, 0.01729265299623784)\n",
      "(3042570996, 0.017220262192581017)\n",
      "(3039321886, 0.015622627381174118)\n",
      "(3082766914, 0.014498603525010737)\n",
      "\n",
      "TOTAL ITERATIONS TO COMPUTE PAGERANK VALUES: 38\n"
     ]
    }
   ],
   "source": [
    "print(\"PAGERANK OUTPUT:\")\n",
    "print(\"    PAGE          USER RANK\")\n",
    "for i in pageranks:\n",
    "    print(i)\n",
    "print()    \n",
    "print(\"TOTAL ITERATIONS TO COMPUTE PAGERANK VALUES:\" , iterations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1.3: Improving PageRank (10 points)\n",
    "In the many years since PageRank was introduced, there have been many improvements and extensions. For this part, you should experiment with one such improvement and then compare the results you get with the original results in Part 1.2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here add your code\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "def ImprovedPageRanker1(C,nodes, maxerr = .000001):\n",
    "    \n",
    "    n = C.shape[0]\n",
    "    matrix = np.zeros((n, n))            \n",
    "    initial_value = 1 / n\n",
    "    ranks =np.ones((n,1)).dot(initial_value) # initial matrix(1003 x 1)   \n",
    "    n_iterations = 0\n",
    "    delta = 1.0\n",
    "    newRank= np.zeros((n,1))\n",
    "    for i in range(0,n):\n",
    "        matrix[i]=np.divide(C[i],sum(C[i]))\n",
    "        if np.any(np.isnan(matrix[i])) == True :\n",
    "            matrix[i]=np.add(C[i],(1/len(C[i])))\n",
    "            \n",
    "    new_matrix = matrix.transpose()\n",
    "    teleport = np.ones((n,n))\n",
    "    H = new_matrix*(1-0.9) + teleport*((0.9)/n)\n",
    "        \n",
    "        \n",
    "    while delta > maxerr:\n",
    "        \n",
    "        newRank = H.dot(ranks)\n",
    "        \n",
    "        mean_value = sum(newRank)/len(newRank)\n",
    "        newr = newRank/(math.sqrt(mean_value))\n",
    "        n_iterations += 1\n",
    "        delta = sum(abs(newRank[node] - ranks[node]) for node in range(0,n))\n",
    "        ranks = newr\n",
    "   \n",
    "    out=[]\n",
    "    for j in range(len(newRank)):\n",
    "        a = newRank[j]\n",
    "        out.append(a[0])\n",
    "    \n",
    "  \n",
    "    dicts = {}\n",
    "    keys = nodes\n",
    "    values = out\n",
    "    \n",
    "    for i in range(len(keys)):\n",
    "        dicts[keys[i]] = values[i]    \n",
    "    \n",
    "    \n",
    "    sorted_d = sorted(dicts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "   \n",
    "    return sorted_d[:10], n_iterations\n",
    " \n",
    "    # this is the revised algorithm, we are taking mean and normalising values\n",
    "    #itertions have reduced and pages differ after changing H matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ipageranks, Iiterations  = ImprovedPageRanker1(graph,nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPROVED PAGERANK OUTPUT 1:\n",
      "    PAGE          USER RANK\n",
      "(3039321886, 3.3097731245742077)\n",
      "(571198546, 3.28615128332632)\n",
      "(1183906148, 3.2079643141947143)\n",
      "(1638625987, 3.1854343483904914)\n",
      "(3042570996, 2.9523969456686885)\n",
      "(3019659587, 2.856835326849231)\n",
      "(3077695572, 2.833448377570785)\n",
      "(3154266823, 2.741560176947009)\n",
      "(1358345766, 2.6515802801212423)\n",
      "(3068694151, 2.4004042693293273)\n",
      "\n",
      "TOTAL ITERATIONS TO COMPUTE PAGERANK VALUES: 8\n"
     ]
    }
   ],
   "source": [
    "print(\"IMPROVED PAGERANK OUTPUT 1:\")\n",
    "print(\"    PAGE          USER RANK\")\n",
    "for i in Ipageranks:\n",
    "    print(i)\n",
    "print()    \n",
    "print(\"TOTAL ITERATIONS TO COMPUTE PAGERANK VALUES:\" , Iiterations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "IMPROVED PAGERANK 1 \n",
    "\n",
    "Source : http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.3.3964&rep=rep1&type=pdf\n",
    "\n",
    "In this improved version, I have implemented the following formulae from the paper cited above to calculate my H matrix:\n",
    " M' = (1-D)*M + D*[1/N]nxn where D is the damping factor and N total number of nodes\n",
    " \n",
    " Additionally, in my while loop, I have taken the mean value of calculated pageranks and normalised my new_pagerank\n",
    " with the mean value before updating the rank vector.\n",
    " \n",
    " The following changes were observed after applying these changes:\n",
    " 1) Total number of iterations required to compute pagerank reduced with the improved approach.\n",
    " 2) Pageranks returned with highest relevance differed with different pagerank values.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import eigs\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "def ImprovedPageRanker2(C,nodes, maxerr = .000001):\n",
    "    n = C.shape[0] #5\n",
    "    matrix = np.zeros((n, n))            \n",
    "    initial_value = 1 / n\n",
    "    ranks =np.ones((n,1)).dot(initial_value) # initial matrix(1003 x 1)   \n",
    "    n_iterations = 0\n",
    "    delta = 1.0\n",
    "    newRank= np.zeros((n,1))\n",
    "    for i in range(0,n):\n",
    "        matrix[i]=np.divide(C[i],sum(C[i]))\n",
    "        if np.any(np.isnan(matrix[i])) == True :\n",
    "            matrix[i]=np.add(C[i],(1/len(C[i])))\n",
    "            \n",
    "    new_matrix = matrix.transpose()\n",
    "    teleport = np.ones((n,n))\n",
    "    H = new_matrix*(0.9) + teleport*((1-0.9)/n)\n",
    "   \n",
    "    \n",
    "    vals, vecs = eigs(np.array(new_matrix), k=1)\n",
    "    \n",
    "   \n",
    "    eigenvector = []\n",
    "    for vec in vecs:\n",
    "        eigenvector.append(vec[0])\n",
    "\n",
    "    \n",
    "    dicts = {}\n",
    "    keys = nodes\n",
    "    values = eigenvector\n",
    "    \n",
    "    for i in range(len(keys)):\n",
    "        dicts[keys[i]] = values[i]    \n",
    "    \n",
    "    \n",
    "    sorted_d = sorted(dicts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "   \n",
    "    return sorted_d[:10], n_iterations\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "I2pageranks, I2iterations = ImprovedPageRanker2(graph,nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PAGERANK OUTPUT:\n",
      "    PAGE          USER RANK\n",
      "(1183906148, (0.372988137447679+0j))\n",
      "(2598548166, (0.23940538393235555+0j))\n",
      "(3019659587, (0.23343298622775943+0j))\n",
      "(3077695572, (0.22922291560492608+0j))\n",
      "(3154266823, (0.20421683088770742+0j))\n",
      "(3068694151, (0.2032681066484863+0j))\n",
      "(3042570996, (0.2032485430333665+0j))\n",
      "(3264645911, (0.1812099104137282+0j))\n",
      "(3082766914, (0.1792897095035943+0j))\n",
      "(571198546, (0.1719584073564121+0j))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"IMPROVED PAGERANK OUTPUT 2:\")\n",
    "print(\"    PAGE          USER RANK\")\n",
    "for i in I2pageranks:\n",
    "    print(i)\n",
    "print()    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plus be sure to describe your extension (what is it? \n",
    "# why did you choose it?) and your comparison to Part 1.2\n",
    "'''\n",
    "IMPROVED PAGERANK 2\n",
    "\n",
    "In this improved version, I have computed the nomalised matrix from graph and applied it to eigs function to\n",
    "generate eigenvectors. The eignvectors generated will be the pageranks generated.\n",
    "\n",
    " The following changes were observed after applying these changes:\n",
    " 1) Total number of iterations required to compute pagerank were nil with the improved approach as we dont\n",
    "    need to iterate through to generate eigenvectors.\n",
    " 2) Pageranks returned with highest relevance differed with different pagerank values.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Learning to Rank (40 points)\n",
    "\n",
    "For this part, we're going to play with some Microsoft LETOR data that has query-document relevance judgments. Let's see how learning to rank works in practice. \n",
    "\n",
    "First, you will need to download the MQ2008.zip file from the Resources tab on Piazza. This is data from the [Microsoft Research IR Group](https://www.microsoft.com/en-us/research/project/letor-learning-rank-information-retrieval/).\n",
    "\n",
    "The data includes 15,211 rows. Each row is a query-document pair. The first column is a relevance label of this pair (0,1 or 2--> the higher value the more related), the second column is query id, the following columns are features, and the end of the row is comment about the pair, including id of the document. A query-document pair is represented by a 46-dimensional feature vector. Features are a numeric value describing a document and query such as TFIDF, BM25, Page Rank, .... You can find compelete description of features from [here](https://arxiv.org/ftp/arxiv/papers/1306/1306.2597.pdf).\n",
    "\n",
    "The good news for you is the dataset is ready for analysis: It has already been split into 5 folds (see the five folders called Fold1, ..., Fold5).\n",
    "\n",
    "\n",
    "## Part 2.1: Build Point-wise Learning to Rank  (20 points)\n",
    "First, you should build a point-wise Learning to Rank framework. \n",
    "1. You could train a binary classification model like SVM or logistic regression on the train file. In this case, 0 is treated as negative (irrelevant) sample and 1, 2 are treated as positive (relevant) sample.\n",
    "2. You apply the already trained model to predict the scores for documents on test file.\n",
    "3. Order the documents based on the scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "add your results and discussion here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define file names\n",
    "\n",
    "#Train files\n",
    "train_txt_1 = \"train1.txt\"\n",
    "train_csv_1 = \"trainc1.csv\"\n",
    "train_txt_2 = \"train2.txt\"\n",
    "train_csv_2 = \"trainc2.csv\"\n",
    "train_txt_3 = \"train3.txt\"\n",
    "train_csv_3 = \"trainc3.csv\"\n",
    "train_txt_4 = \"train4.txt\"\n",
    "train_csv_4 = \"trainc4.csv\"\n",
    "train_txt_5 = \"train5.txt\"\n",
    "train_csv_5 = \"trainc5.csv\"\n",
    "\n",
    "#Test Files\n",
    "test_txt_1 = \"test1.txt\"\n",
    "test_csv_1 = \"testc1.csv\"\n",
    "test_txt_2 = \"test2.txt\"\n",
    "test_csv_2 = \"testc2.csv\"\n",
    "test_txt_3 = \"test3.txt\"\n",
    "test_csv_3 = \"testc3.csv\"\n",
    "test_txt_4 = \"test4.txt\"\n",
    "test_csv_4 = \"testc4.csv\"\n",
    "test_txt_5 = \"test5.txt\"\n",
    "test_csv_5 = \"testc5.csv\"\n",
    "\n",
    "#Validation Files\n",
    "vali_txt_1 = \"vali1.txt\"\n",
    "vali_csv_1 = \"valic1.csv\"\n",
    "vali_txt_2 = \"vali2.txt\"\n",
    "vali_csv_2 = \"valic2.csv\"\n",
    "vali_txt_3 = \"vali3.txt\"\n",
    "vali_csv_3 = \"valic3.csv\"\n",
    "vali_txt_4 = \"vali4.txt\"\n",
    "vali_csv_4 = \"valic4.csv\"\n",
    "vali_txt_5 = \"vali5.txt\"\n",
    "vali_csv_5 = \"valic5.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "def parse_data(inputf,outputf):\n",
    "    qid = []\n",
    "    docid = []\n",
    "    original_labels = []\n",
    "    rows=[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,'label']\n",
    "    \n",
    "    with open(outputf, 'w+') as csvFile:\n",
    "        writer = csv.writer(csvFile) \n",
    "        writer.writerow(rows)\n",
    "        \n",
    "        for f in open(inputf,\"r\"): \n",
    "            rowval=[]\n",
    "            values=f.split()\n",
    "            r=2;\n",
    "            \n",
    "            for i in range(1,47): \n",
    "                if (int(values[r].split(\":\")[0]))!=i: \n",
    "                    rowval.append(\"\")\n",
    "                    continue\n",
    "                rowval.append(values[r].split(\":\")[1])\n",
    "                r += 1 \n",
    "                \n",
    "            temp = int(values[0])\n",
    "            original_labels.append(temp)\n",
    "            \n",
    "            if (temp==1) or (temp==2):\n",
    "                temp = 1\n",
    "                \n",
    "            rowval.append(temp)\n",
    "            qid.append(int(values[1].split(\":\")[1]))\n",
    "            docid.append(values[50])\n",
    "            writer.writerow(rowval)\n",
    "            \n",
    "    csvFile.close()\n",
    "    return qid,docid,original_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fetch Query Ids and DocIds\n",
    "\n",
    "qid1 , docid1 , org1 = parse_data(train_txt_1,train_csv_1)\n",
    "qid2 , docid2 , org2  = parse_data(train_txt_2,train_csv_2)\n",
    "qid3 , docid3,  org3 = parse_data(train_txt_3,train_csv_3)\n",
    "qid4 , docid4,  org4 = parse_data(train_txt_4,train_csv_4)\n",
    "qid5 , docid5,  org5 = parse_data(train_txt_5,train_csv_5)\n",
    "\n",
    "tqid1 , tdocid1, torg1 = parse_data(test_txt_1,test_csv_1)\n",
    "tqid2 , tdocid2,torg2 = parse_data(test_txt_2,test_csv_2)\n",
    "tqid3 , tdocid3,torg3 = parse_data(test_txt_3,test_csv_3)\n",
    "tqid4 , tdocid4,torg4 = parse_data(test_txt_4,test_csv_4)\n",
    "tqid5 , tdocid5,torg5 = parse_data(test_txt_5,test_csv_5)\n",
    "\n",
    "vqid1 , vdocid1, vorg1= parse_data(vali_txt_1,vali_csv_1)\n",
    "vqid2 , vdocid2 ,vorg2= parse_data(vali_txt_2,vali_csv_2)\n",
    "vqid3 , vdocid3 ,vorg3= parse_data(vali_txt_3,vali_csv_3)\n",
    "vqid4 , vdocid4 ,vorg4= parse_data(vali_txt_4,vali_csv_4)\n",
    "vqid5 , vdocid5 ,vorg5= parse_data(vali_txt_5,vali_csv_5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 'label'\n",
    "features = ['1','2','3','4','5','6','7','8','9','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40','41','42','43','44','45','46']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createDataFrame(filename):\n",
    "    dframe = pd.read_csv(filename)\n",
    "    X_train = dframe[features]\n",
    "    Y_train = dframe[[label]]\n",
    "    return X_train, Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch DataFrame format Value\n",
    "X_train1, Y_train1 = createDataFrame(\"trainc1.csv\")\n",
    "X_train2, Y_train2 = createDataFrame(\"trainc2.csv\")\n",
    "X_train3, Y_train3 = createDataFrame(\"trainc3.csv\")\n",
    "X_train4, Y_train4 = createDataFrame(\"trainc4.csv\")\n",
    "X_train5, Y_train5 = createDataFrame(\"trainc5.csv\")\n",
    "\n",
    "X_test1, Y_test1 = createDataFrame(\"testc1.csv\")\n",
    "X_test2, Y_test2 = createDataFrame(\"testc2.csv\")\n",
    "X_test3, Y_test3 = createDataFrame(\"testc3.csv\")\n",
    "X_test4, Y_test4 = createDataFrame(\"testc4.csv\")\n",
    "X_test5, Y_test5 = createDataFrame(\"testc5.csv\")\n",
    "\n",
    "X_vali1, Y_vali1 = createDataFrame(\"valic1.csv\")\n",
    "X_vali2, Y_vali2 = createDataFrame(\"valic2.csv\")\n",
    "X_vali3, Y_vali3 = createDataFrame(\"valic3.csv\")\n",
    "X_vali4, Y_vali4 = createDataFrame(\"valic4.csv\")\n",
    "X_vali5, Y_vali5 = createDataFrame(\"valic5.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.simplefilter('ignore')\n",
    "cValues = {}\n",
    "def calculateC(xlabel,ylabel,xval,yval):\n",
    "    for i in range(1,10):\n",
    "        svm = SVC(C=i,probability=True)\n",
    "        svm.fit(xlabel, ylabel)\n",
    "        cValues[i] = svm.score(xval, yval)\n",
    "    return cValues   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "cscore1 = calculateC(X_train1,Y_train1,X_vali1,Y_vali1)\n",
    "cscore2 = calculateC(X_train2,Y_train2,X_vali2,Y_vali2)\n",
    "cscore3 = calculateC(X_train3,Y_train3,X_vali3,Y_vali3)\n",
    "cscore4 = calculateC(X_train4,Y_train4,X_vali4,Y_vali4)\n",
    "cscore5 = calculateC(X_train5,Y_train5,X_vali5,Y_vali5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "max_1 = findmaxaccuracy(cscore1)\n",
    "max_2 = findmaxaccuracy(cscore2)\n",
    "max_3 = findmaxaccuracy(cscore3)\n",
    "max_4 = findmaxaccuracy(cscore4)\n",
    "max_5 = findmaxaccuracy(cscore5)\n",
    "highest_c_value =max(max_1,max_2,max_3,max_4,max_5)\n",
    "\n",
    "print(highest_c_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findmaxaccuracy(cscore):\n",
    "    \n",
    "    for key,value in cscore.items():\n",
    "        cscore[key] = cscore[key]/5\n",
    "    \n",
    "    cmax = max(cscore, key=cscore.get)\n",
    "    return cmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictionprobability(highest_c_value,xlabel,ylabel,xtest):\n",
    "    svm = SVC(C = highest_c_value, kernel = 'rbf',probability=True)\n",
    "    svm.fit(xlabel, ylabel)\n",
    "    prediction = svm.predict_log_proba(xtest)\n",
    "    return prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction Values\n",
    "\n",
    "pred1 = predictionprobability(highest_c_value,X_train1, Y_train1,X_test1)\n",
    "pred2 = predictionprobability(highest_c_value,X_train2, Y_train2,X_test2)\n",
    "pred3 = predictionprobability(highest_c_value,X_train3, Y_train3,X_test3)\n",
    "pred4 = predictionprobability(highest_c_value,X_train4, Y_train4,X_test4)\n",
    "pred5 = predictionprobability(highest_c_value,X_train5, Y_train5,X_test5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#qdict = defaultdict(list)\n",
    "def querymapping(qid,torg,pred):\n",
    "    qdict = defaultdict(list)\n",
    "    i=0\n",
    "    for queryid in qid:\n",
    "        qdict[qid[i]].append([pred[i][1],torg[i]]) \n",
    "       \n",
    "        i+=1\n",
    "    return qdict    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "querymapping1 = querymapping(tqid1,torg1,pred1)\n",
    "querymapping2 = querymapping(tqid2,torg2,pred2)\n",
    "querymapping3 = querymapping(tqid3,torg3,pred3)\n",
    "querymapping4 = querymapping(tqid4,torg4,pred4)\n",
    "querymapping5 = querymapping(tqid5,torg5,pred5) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2.2: NDCG (20 points)\n",
    "\n",
    "Based on your prediction file (results could be ranked by scores in the prediction file) and ground-truth (i.e., 0,1,2) in the test file, calculate NDCG for each query. Report average NDCG for all queries in the five-fold cross validation.\n",
    "\n",
    "For NDCG, please bulid your own function rather then using any package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NDCG(prob_rel,orginal_rel):\n",
    "    count = 0\n",
    "    DCG = 0\n",
    "    IDCG = 0  \n",
    "    iteration_len =len(prob_rel)\n",
    "    for i in range(iteration_len):\n",
    "        if (count!=10):\n",
    "            DCG += ((2**prob_rel[i][1])-1)/(math.log(1+i+1))\n",
    "            IDCG += ((2**orginal_rel[i][1])-1)/(math.log(1+i+1))\n",
    "            count +=1\n",
    "    if IDCG == 0:\n",
    "        NDCG = 0\n",
    "    else:\n",
    "        NDCG = (DCG/IDCG)\n",
    "    return NDCG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meanValNDCG(querymapping):\n",
    "    ndcg_val = []\n",
    "    for i in querymapping:\n",
    "        sortby_prob = []\n",
    "        sortby_relevance = []\n",
    "        for j in range(len(querymapping[i])):\n",
    "            sortby_prob.append(querymapping[i][j])\n",
    "            sortby_relevance.append(querymapping[i][j])  \n",
    "        sortby_prob.sort(reverse = True)\n",
    "        sortby_relevance.sort(key = lambda x: x[1],reverse=True) \n",
    "        ndcg_val.append(NDCG(sortby_prob,sortby_relevance))\n",
    "        output = mean(ndcg_val)\n",
    "    return output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "ndcg1 = meanValNDCG(querymapping1)\n",
    "ndcg2 = meanValNDCG(querymapping2)\n",
    "ndcg3 = meanValNDCG(querymapping3)\n",
    "ndcg4 = meanValNDCG(querymapping4)\n",
    "ndcg5 = meanValNDCG(querymapping5)\n",
    "final_ndcg = (ndcg1+ ndcg2 + ndcg3 + ndcg4 + ndcg5)/5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printNDCGValues():\n",
    "    print(\"{} : {}\".format(\"NDCG VALUE FOR FOLD 1\", ndcg1))\n",
    "    print(\"{} : {}\".format(\"NDCG VALUE FOR FOLD 2\", ndcg2))\n",
    "    print(\"{} : {}\".format(\"NDCG VALUE FOR FOLD 3\", ndcg3))\n",
    "    print(\"{} : {}\".format(\"NDCG VALUE FOR FOLD 4\", ndcg4))\n",
    "    print(\"{} : {}\".format(\"NDCG VALUE FOR FOLD 5\", ndcg5))\n",
    "    print()\n",
    "    print(\"{} : {}\".format(\"AVERAGE NDCG VALUE FOR ALL FOLDS\", final_ndcg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG VALUE FOR FOLD 1 : 0.44504962468160053\n",
      "NDCG VALUE FOR FOLD 2 : 0.436514126463978\n",
      "NDCG VALUE FOR FOLD 3 : 0.4546122672042186\n",
      "NDCG VALUE FOR FOLD 4 : 0.507081931367985\n",
      "NDCG VALUE FOR FOLD 5 : 0.5118200007055816\n",
      "\n",
      "AVERAGE NDCG VALUE FOR ALL FOLDS : 0.47101559008467275\n"
     ]
    }
   ],
   "source": [
    "printNDCGValues()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (BONUS) Pairwise Learning to Rank (5 points)\n",
    "\n",
    "Rather than use the point-wise approach as in Part 2.1, instead try to implement a paiwise approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "def pairwiseX(xtrain):\n",
    "    X, yp, diff = [], [], []\n",
    "    X_new = []\n",
    "    X.append(X_train1['1'])\n",
    "    for j in range(1,46):\n",
    "        row1 = str(j)\n",
    "        row2 = str(j+1)\n",
    "        X.append(xtrain[row1] - xtrain[row2])\n",
    "    X.append(xtrain['46'])\n",
    "    Dict = {} \n",
    "    for k in range(len(X[1])):  #9630#\n",
    "        Dict[1] = X[1][k]\n",
    "\n",
    "    for i in range(2,46):  # 46\n",
    "        X_new = []\n",
    "        for q in range(len(X[i])):  #9630\n",
    "            X_new.append(X[i][q])\n",
    "        \n",
    "        #print(len(X_new))  #9630\n",
    "        Dict[i] = X_new\n",
    "    \n",
    "    for f in range(len(X[46])):  #9630\n",
    "        Dict[46] = X[46][f]\n",
    "    return Dict    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = pairwiseX(X_train1)\n",
    "data2 = pairwiseX(X_train2)\n",
    "data3 = pairwiseX(X_train3)\n",
    "data4 = pairwiseX(X_train4)\n",
    "data5 = pairwiseX(X_train5)\n",
    "\n",
    "df1 = pd.DataFrame(data1)\n",
    "df2 = pd.DataFrame(data2)\n",
    "df3 = pd.DataFrame(data3)\n",
    "df4 = pd.DataFrame(data4)\n",
    "df5 = pd.DataFrame(data5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwiseY(ytrain):\n",
    "    k = 0\n",
    "    yp, diff = [], []\n",
    "\n",
    "    diff.append(ytrain['label'][0]) \n",
    "    yp.append(np.sign(diff[-1]))    \n",
    "    for i in range(0,len(ytrain['label'])-1):\n",
    "        diff.append(ytrain['label'][i] - ytrain['label'][i+1])\n",
    "    \n",
    "        yp.append(np.sign(diff[-1]))\n",
    "    if yp[-1] != (-1) ** k:\n",
    "        yp[-1] *= -1\n",
    "   \n",
    "        diff[-1] *= -1\n",
    "       \n",
    "        k += 1\n",
    "    yp, diff = map(np.asanyarray, (yp, diff))\n",
    "    \n",
    "    return yp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "yp1 = pairwiseY(Y_train1)\n",
    "yp2 = pairwiseY(Y_train2)\n",
    "yp3 = pairwiseY(Y_train3)\n",
    "yp4 = pairwiseY(Y_train4)\n",
    "yp5 = pairwiseY(Y_train5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred1_new = predictionprobability(10,df1,yp1,X_test1)\n",
    "pred2_new = predictionprobability(10,df2,yp2,X_test2)\n",
    "pred3_new = predictionprobability(10,df3,yp3,X_test3)\n",
    "pred4_new = predictionprobability(10,df4,yp4,X_test4)\n",
    "pred5_new = predictionprobability(10,df5,yp5,X_test5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collaboration declarations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If you collaborated with anyone (see Collaboration policy at the top of this homework), you can put your collaboration declarations here.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Part 1.1, 1.2 , 1.3 : Implemented on my own post understanding of the concept.\n",
    "Part 2.1 : Discussed with a fellow classmate and implemented the code on my own\n",
    "Part 2.2 : Discussed with a classmate on the formula to be applied    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
