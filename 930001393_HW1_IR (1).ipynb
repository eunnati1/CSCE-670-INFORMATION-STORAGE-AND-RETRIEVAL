{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CSCE 670 :: Information Storage and Retrieval :: Texas A&M University :: Spring 2020\n",
    "\n",
    "\n",
    "# Homework 1:  Information Retrieval Basics\n",
    "\n",
    "### 100 points [7% of your final grade]\n",
    "\n",
    "### Due: January 31 (Friday) by 11:59pm\n",
    "\n",
    "*Goals of this homework:* In this homework you will get first hand experience building a text-based mini search engine. In particular, there are three main learning objectives: (i) the basics of tokenization (e.g. stemming, case-folding, etc.) and its effect on information retrieval; (ii) basics of index building and Boolean retrieval; and (iii) basics of the Vector Space model and ranked retrieval.\n",
    "\n",
    "*Submission instructions (eCampus):* To submit your homework, rename this notebook as `UIN_hw1.ipynb`. For example, my homework submission would be something like `555001234_hw1.ipynb`. Submit this notebook via eCampus (look for the homework 1 assignment there). Your notebook should be completely self-contained, with the results visible in the notebook. We should not have to run any code from the command line, nor should we have to run your code within the notebook (though we reserve the right to do so). So please run all the cells for us, and then submit.\n",
    "\n",
    "*Late submission policy:* For this homework, you may use as many late days as you like (up to the 5 total allotted to you).\n",
    "\n",
    "*Collaboration policy:* You are expected to complete each homework independently. Your solution should be written by you without the direct aid or help of anyone else. However, we believe that collaboration and team work are important for facilitating learning, so we encourage you to discuss problems and general problem approaches (but not actual solutions) with your classmates. You may post on Piazza, search StackOverflow, etc. But if you do get help in this way, you must inform us by **filling out the Collaboration Declarations at the bottom of this notebook**. \n",
    "\n",
    "*Example: I found helpful code on stackoverflow at https://stackoverflow.com/questions/11764539/writing-fizzbuzz that helped me solve Problem 2.*\n",
    "\n",
    "The basic rule is that no student should explicitly share a solution with another student (and thereby circumvent the basic learning process), but it is okay to share general approaches, directions, and so on. If you feel like you have an issue that needs clarification, feel free to contact either me or the TA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "The dataset is collected from Quizlet (https://quizlet.com), a website where users can generated their own flashcards. Each flashcard generated by a user is made up of an entity on the front and a definition describing or explaining the entity correspondingly on the back. We treat entities on each flashcard's front as the queries and the definitions on the back of flashcards as the documents. Definitions (documents) are relevant to an entity (query) if the definitions are from the back of the entity's flashcard; otherwise definitions are not relevant. **In this homework, queries and entities are interchangeable as well as documents and definitions.**\n",
    "\n",
    "The format of the dataset is like this:\n",
    "\n",
    "**query \\t document id \\t document**\n",
    "\n",
    "Examples:\n",
    "\n",
    "decision tree\t\\t 27946 \\t\tshow complex processes with multiple decision rules.  display decision logic (if statements) as set of (nodes) questions and branches (answers).\n",
    "\n",
    "where \"decision tree\" is the entity in the front of a flashcard and \"show complex processes with multiple decision rules.  display decision logic (if statements) as set of (nodes) questions and branches (answers).\" is the definition on the flashcard's back and \"27946\" is the id of the definition. Naturally, this document is relevant to the query.\n",
    "\n",
    "false positive rate\t\\t 686\t\\t fall-out; probability of a false alarm\n",
    "\n",
    "where document 686 is not relevant to query \"decision tree\" because the entity of \"fall-out; probability of a false alarm\" is \"false positive rate\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: Parsing (20 points)\n",
    "\n",
    "First, you should tokenize documents (definitions) using **whitespaces and punctuations as delimiters**. Your parser needs to also provide the following three pre-processing options:\n",
    "* Remove stop words: use nltk stop words list (from nltk.corpus import stopwords)\n",
    "* Stemming: use [nltk Porter stemmer](http://www.nltk.org/api/nltk.stem.html#module-nltk.stem.porter)\n",
    "* Remove any other strings that you think are less informative or nosiy.\n",
    "\n",
    "Please note that you should stick to the stemming package listed above. Otherwise, given the same query, the results generated by your code can be different from others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuration options\n",
    "remove_stopwords = True  # or false\n",
    "use_stemming = True # or false\n",
    "remove_otherNoise = True # or false"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import math\n",
    "ps = PorterStemmer() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FetchData(filename):\n",
    "    f = open(filename, encoding = \"utf8\")\n",
    "            \n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = FetchData('homework_1_data.txt')\n",
    "ps = PorterStemmer() \n",
    "stop_words = set(stopwords.words('english')) \n",
    "count_stopwords=0\n",
    "filtered_sentence = [] \n",
    "stemmed = []\n",
    "unique_list = []\n",
    "\n",
    "for line in f:\n",
    "    \n",
    "    s = line.split('\\t')[2]\n",
    "    out = s.translate( str.maketrans(\"\", \"\", string.punctuation))\n",
    "    tokens= word_tokenize(out)\n",
    "    unique_list.append(tokens)\n",
    "    unique_words = set(tokens)\n",
    "    for w in unique_words: \n",
    "        if w not in stop_words: \n",
    "            filtered_sentence.append(w)\n",
    "            stemmed.append(ps.stem(w))\n",
    "    \n",
    "#print(stemmed)   \n",
    "unique_words = set(stemmed) \n",
    "unique_words_filtered = set(filtered_sentence) \n",
    "\n",
    "flat_list = []\n",
    "for sublist in unique_list:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)\n",
    "unique_words_wout_processing = set(flat_list) \n",
    "\n",
    "Processed_length = len(unique_words)\n",
    "filtered_length = len(unique_words_filtered)\n",
    "without_processing = len(unique_words_wout_processing)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write for remove other noise\n",
    "other_noise =[]\n",
    "for wrd in unique_words:\n",
    "        ch =0\n",
    "        for c in wrd:\n",
    "            if ord(c)>128:\n",
    "                ch =1\n",
    "                break\n",
    "        if(ch ==0):\n",
    "            other_noise.append(wrd)\n",
    "other_noise_removed =len(other_noise)           \n",
    "#print(other_noise_removed)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None of pre-processing options =  19388\n",
      "remove stop words = 19261\n",
      "remove stop words + stemming = 13344\n",
      "remove stop words + stemming + remove other noise =  12714\n"
     ]
    }
   ],
   "source": [
    "print(\"None of pre-processing options = \" , without_processing)\n",
    "print(\"remove stop words =\" ,filtered_length) \n",
    "print(\"remove stop words + stemming =\" ,Processed_length) \n",
    "print(\"remove stop words + stemming + remove other noise = \" ,other_noise_removed) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "\n",
    "Once you have your parser working, you should report here the size of your dictionary under the four cases. That is, how many unique tokens do you have with stemming on and casefolding on? And so on. You should fill in the following\n",
    "\n",
    "* None of pre-processing options      = ??\n",
    "* remove stop words       = ??\n",
    "* remove stop words + stemming       = ??\n",
    "* remove stop words + stemming  + remove other noise     = ??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: Boolean Retrieval (30 points)\n",
    "\n",
    "In this part you build an inverted index to support Boolean retrieval. We only require your index to support AND queries. In other words, your index does not have to support OR, NOT, or parentheses. Also, we do not explicitly expect to see AND in queries, e.g., when we query **relational model**, your search engine should treat it as **relational** AND **model**.\n",
    "\n",
    "Search for the queries below using your index and print out matching documents (for each query, print out 5 matching documents):\n",
    "* relational database\n",
    "* garbage collection\n",
    "* retrieval model\n",
    "\n",
    "Please use the following format to present your results:\n",
    "* query: relational database\n",
    "* result 1:\n",
    "* entity: database management system\n",
    "* definition id: 656\n",
    "* definition: software system used to manage databases\n",
    "* result 2:\n",
    "* ......\n",
    "* query: garbage collection\n",
    "* ......\n",
    "* query: retrieval model\n",
    "* ......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import wordpunct_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer \n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = FetchData('homework_1_data.txt')\n",
    "document_file=[]\n",
    "document_list =[]\n",
    "document_entity = []\n",
    "for file in f:\n",
    "    definition = file.split('\\t')[2]\n",
    "    docidx =file.split('\\t')[1]\n",
    "    entity = file.split('\\t')[0]\n",
    "    document_file.append(definition)\n",
    "    document_list.append(docidx)\n",
    "    document_entity.append(entity)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "def invert_dict(vocab, original):\n",
    "    inverted_index = {}\n",
    "\n",
    "    for word in vocab:\n",
    "        inverted_index[word] = {}\n",
    "        inverted_index[word] = set()\n",
    "\n",
    "    for key, value in original.items():\n",
    "        for word in value:\n",
    "            inverted_index[word].add(key)\n",
    "            \n",
    "    return inverted_index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = FetchData('homework_1_data.txt')\n",
    "token_file =[]\n",
    "for files in f:\n",
    "    tokens = word_tokenize(files.split('\\t')[2])\n",
    "    unique_words = set(tokens)\n",
    "    token_file.append(unique_words)\n",
    "    \n",
    "flat_list = []\n",
    "for sublist in token_file:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)\n",
    "vocab = set(flat_list)\n",
    "#print(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use this to be given into inverted index mapping\n",
    "tf ={}\n",
    "\n",
    "f = FetchData('homework_1_data.txt')\n",
    "ps = PorterStemmer() \n",
    "stop_words = set(stopwords.words('english'))\n",
    "token_file = []\n",
    "for files in f:\n",
    "    entity, docid, definition = files.split('\\t')\n",
    "    tf[docid] = {}\n",
    "    tokens = wordpunct_tokenize(definition)\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    tokens = [ps.stem(word) for word in tokens]\n",
    "    tokens = [word for word in tokens if len(word) > 0]\n",
    "    \n",
    "    for token in tokens:\n",
    "        if token not in tf[docid]:\n",
    "            tf[docid][token] = 1\n",
    "        else:\n",
    "            tf[docid][token] += 1\n",
    "            \n",
    "    token_file.append(tokens)\n",
    "    \n",
    "flat_list = []\n",
    "for sublist in token_file:\n",
    "    for item in sublist:\n",
    "        flat_list.append(item)\n",
    "vocab1 = set(flat_list)\n",
    "#print(vocab1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = FetchData('homework_1_data.txt')\n",
    "ps = PorterStemmer() \n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = FetchData('homework_1_data.txt')\n",
    "def original_dict(f):\n",
    "    original_dict = {}\n",
    "\n",
    "    for line in f:\n",
    "        entity, docid, definition = line.split('\\t')\n",
    "        original_dict[docid] = wordpunct_tokenize(definition)\n",
    "        original_dict[docid] = [word.lower() for word in original_dict[docid]]\n",
    "        original_dict[docid] = [word for word in original_dict[docid] if word not in stop_words]\n",
    "        original_dict[docid] = [ps.stem(word) for word in original_dict[docid]]\n",
    "        original_dict[docid] = [word for word in original_dict[docid] if len(word) > 0]\n",
    "        #original_dict[docid] = [ps.stem(word) if word not in stop_words for word in original_dict[docid]]\n",
    "        #original_dict[docid] = re.sub(r\"\\s*{.*}\\s*\", \" \", original_dict[docid])\n",
    "            \n",
    "    return original_dict\n",
    "#print(original_dict(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = FetchData('homework_1_data.txt')\n",
    "def invert_dict(vocab, original):\n",
    "    inverted_index = {}\n",
    "\n",
    "    for word in vocab:\n",
    "        inverted_index[word] = {}\n",
    "        inverted_index[word] = set()\n",
    "\n",
    "    #print(original)\n",
    "    \n",
    "    for key, value in original.items():\n",
    "        #print(value)\n",
    "        for word in value:\n",
    "            inverted_index[word].add(key)\n",
    "            \n",
    "    return inverted_index \n",
    "\n",
    "#print(query2)\n",
    "#print(invert_dict(vocab1,original_dict(f)).get(query))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnval(output,query,document_file,document_entity):\n",
    "    print(\"query:\" + query)\n",
    "    for num in range(len(output)):\n",
    "        print(\"result \" + str(num+1) + \":\")\n",
    "        id = int(output[num]) \n",
    "        print(\"entity:\" + document_entity[int(id)])\n",
    "        print(\"definition id:\" + str(id))\n",
    "        print(\"definition:\" + document_file[id])\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for the input using your index and print out ids of matching documents.\n",
    "f = FetchData('homework_1_data.txt')\n",
    "inverted_index = invert_dict(vocab1,original_dict(f))\n",
    "\n",
    "\n",
    "query1 = ps.stem(\"relational\")\n",
    "val1 = inverted_index[query1]\n",
    "query2 = ps.stem(\"database\")\n",
    "val2 = inverted_index[query2]\n",
    "outputBR = list(val1 & val2)\n",
    "final_output = outputBR[:5]\n",
    "\n",
    "query3 = ps.stem(\"garbage\")\n",
    "val3 = inverted_index[query3]\n",
    "query4 = ps.stem(\"collection\")\n",
    "val4 = inverted_index[query4]\n",
    "outputBR2 = list(val3 & val4)\n",
    "final_output2 = outputBR2[:5]\n",
    "\n",
    "query5 = ps.stem(\"retrieval\")\n",
    "val5 = inverted_index[query5]\n",
    "query6 = ps.stem(\"model\")\n",
    "val6 = inverted_index[query6]\n",
    "outputBR3 = list(val5 & val6)\n",
    "final_output3 = outputBR3[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:relational database\n",
      "result 1:\n",
      "entity:relational model\n",
      "definition id:831\n",
      "definition:a database model that describes data in which all data elements are placed in two-dimensional tables, called relations, which are the logical equivalent of files.\n",
      "\n",
      "result 2:\n",
      "entity:relational database\n",
      "definition id:28160\n",
      "definition:a group of related databases associated by a key, or a common identifying (qualitative) characteristic.\n",
      "\n",
      "result 3:\n",
      "entity:data management\n",
      "definition id:16052\n",
      "definition:data stored in relational databases -tables stored in secondary storage\n",
      "\n",
      "result 4:\n",
      "entity:relational algebra\n",
      "definition id:7135\n",
      "definition:a theoretical way of manipulating a relational database based on set theory\n",
      "\n",
      "result 5:\n",
      "entity:data model\n",
      "definition id:7008\n",
      "definition:model used for planning the org's database that identifies what kind of info is needed, what entities will be created and how they are related to one another\n",
      "\n",
      "None\n",
      "query:garbage collection\n",
      "result 1:\n",
      "entity:garbage collection\n",
      "definition id:21559\n",
      "definition:garbage collection is a feature that automatically deletes unused memory that is no longer being referenced. you cannot force it but you can request it using system.gc() but you should never use that because it slows down your program heavily. once the system thinks an object it ready for collection, it will call finalize() on it which does final cleanup and prepares it do be collected\n",
      "\n",
      "result 2:\n",
      "entity:garbage collection\n",
      "definition id:21555\n",
      "definition:when data is no longer referable (i.e., there are no remaining references to that data available for executable code), it is &\"garbage collected&\" and will be destroyed at some later point in time\n",
      "\n",
      "result 3:\n",
      "entity:garbage collection\n",
      "definition id:21576\n",
      "definition:a class instance is explicitly created by the java code and after use it is automatically destroyed by garbage collection for memory management.\n",
      "\n",
      "result 4:\n",
      "entity:garbage collection\n",
      "definition id:21553\n",
      "definition:garbage collection (gc) is a form of automatic memory management. the garbage collector, or just collector, attempts to reclaim garbage, or memory occupied by objects that are no longer in use by the program.\n",
      "\n",
      "result 5:\n",
      "entity:garbage collection\n",
      "definition id:21554\n",
      "definition:there is a third phase of 2pc called garbage collection. replicas must retain records of past transactions, just in case leader fails. in practice, leader periodically tells replicas to garbage collect.\n",
      "\n",
      "None\n",
      "query:retrieval model\n",
      "result 1:\n",
      "entity:query language\n",
      "definition id:9085\n",
      "definition:used to update and retrieve data that is stored in a data model\n",
      "\n",
      "result 2:\n",
      "entity:online analytical processing\n",
      "definition id:19727\n",
      "definition:tools for retrieving, processing, and modelling data from the data warehouse\n",
      "\n",
      "result 3:\n",
      "entity:web browser\n",
      "definition id:17705\n",
      "definition:-a software application used to locate, retrieve, and display content on the world wide web, including web pages, images, video, and other files -as a client/server model, the browser is the client on a computer that contacts the web server and requests information. the web server sends the information back to the web brows\n",
      "\n",
      "result 4:\n",
      "entity:physical design\n",
      "definition id:10327\n",
      "definition:translate logical model into technical specifications for storing/retrieving data, store data to achieve efficiency and quality\n",
      "\n",
      "result 5:\n",
      "entity:physical design\n",
      "definition id:10341\n",
      "definition:-translate logical model into technical specification for strong/retrieving data -store data to achieve efficiency and quality\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(returnval(final_output,\"relational database\",document_file,document_entity))\n",
    "print(returnval(final_output2,\"garbage collection\",document_file,document_entity))\n",
    "print(returnval(final_output3,\"retrieval model\",document_file,document_entity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observations\n",
    "Could your boolean search engine find relevant documents for these queries? What is the impact of the three pre-processing options? Do they improve your search quality?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    # Part 3: Ranking Documents (50 points) \n",
    "\n",
    "    In this part, your job is to rank the documents that have been retrieved by the Boolean Retrieval component in Part 2, according to their relevance with each query.\n",
    "\n",
    "    ### A: Ranking with simple sums of TF-IDF scores (15 points) \n",
    "    For a multi-word query, we rank documents by a simple sum of the TF-IDF scores for the query terms in the document.\n",
    "    TF is the log-weighted term frequency $1+log(tf)$; and IDF is the log-weighted inverse document frequency $log(\\frac{N}{df})$\n",
    "\n",
    "    **Output:**\n",
    "    For each given query in Part 2, you should just rank the documents retrieved by your boolean search. You only need to output the top-5 results plus the TF-IDF sum score of each of these documents. Please use the following format to present your results:\n",
    "\n",
    "* query: relational database\n",
    "* result 1:\n",
    "* score: 0.1\n",
    "* entity: database management system\n",
    "* definition id: 656\n",
    "* definition: software system used to manage databases\n",
    "* result 2:\n",
    "* ......\n",
    "* query: garbage collection\n",
    "* ......\n",
    "* query: retrieval model\n",
    "* ......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "# hint: you could first call boolean retrieval function in part 2 to find possible relevant documents, \n",
    "# and then rank these documents in this part. Hence, you don't need to rank all documents.\n",
    "total_document = len(document_list)\n",
    "#document_list= all docid list\n",
    "\n",
    "import math\n",
    "#document_file = all defination list\n",
    "def tfidfcal(query, document_list, inverted_index,document_file):\n",
    "    query = parseDefination(query)   #['relat', 'databas']\n",
    "   # print(query)\n",
    "    rank = []\n",
    "    idf_val = {}\n",
    "    #calculating idf value\n",
    "    for word in query:\n",
    "        dftv = len(inverted_index[word])  #1057\n",
    "        #print(dftv)\n",
    "        idfv = math.log10(total_document/dftv)\n",
    "        #print(idfv)\n",
    "        idf_val[word] = idfv\n",
    "    for docid in document_list:\n",
    "        tfidf_score =0\n",
    "       \n",
    "        for word in query:\n",
    "            if word not in inverted_index:\n",
    "                continue\n",
    "            parsedDoc = document_file[int(docid)]\n",
    "            #print(parsedDocument)\n",
    "            word_freq = parsedDoc.count(word)\n",
    "            if(word_freq >0):\n",
    "                #print(word_freq)\n",
    "                tfv = 1+ math.log10(word_freq)\n",
    "                idfv = idf_val[word]\n",
    "                tfidf_score = tfidf_score + tfv*idfv\n",
    "        rank.append((tfidf_score, docid))\n",
    "        rank = sorted(rank, reverse = True)\n",
    "    tfidf_score = [(ranked[1],ranked[0]) for ranked in rank]\n",
    "    return tfidf_score[:5]\n",
    "result1 = tfidfcal('relational database',document_list,inverted_index,document_file)\n",
    "#print(result1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = tfidfcal('relational database',document_list,inverted_index,document_file)\n",
    "result2 = tfidfcal('garbage collection',document_list,inverted_index,document_file)\n",
    "result3 = tfidfcal('retrieval model',document_list,inverted_index,document_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnvalPart3(output,query,document_file,document_entity):\n",
    "    print(\"query:\" + query)\n",
    "    for num in range(len(output)):\n",
    "        print(\"result \" + str(num+1) + \":\")\n",
    "        if(isinstance(output[0],tuple)):\n",
    "            id = output[num][0]\n",
    "            print(\"score: \" + str(output[num][1]))\n",
    "            print(\"entity:\" + document_entity[int(id)])\n",
    "            print(\"definition id:\" + str(id))\n",
    "            print(\"definition:\" + document_file[int(id)])\n",
    "        else:\n",
    "            id = int(output[num]) \n",
    "            print(\"entity:\" + document_entity[int(id)])\n",
    "            print(\"definition id:\" + str(id))\n",
    "            print(\"definition:\" + document_file[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:relational database\n",
      "result 1:\n",
      "score: 4.71733880527531\n",
      "entity:relational algebra\n",
      "definition id:7156\n",
      "definition:- a theoretical language with operations that work on one or more relations to define another relation without changing the original relation(s)  - relation-at-a-time (or set) language in which all tuples, possibly from several relations, are manipulated in one statement without looping  relational algebra, first created by edgar f. codd while at ibm, is a family of algebras with a well-founded semantics used for modelling the data stored in relational databases, and defining queries on it.  the main application of relational algebra is providing a theoretical foundation for relational databases, particularly query languages for such databases, chief among which is sql.\n",
      "\n",
      "result 2:\n",
      "score: 4.357658330802902\n",
      "entity:relational database\n",
      "definition id:28378\n",
      "definition:a type of database system where data is stored in  tables related by common fields. a relational database is the most common type of database used with a personal computer. similar data is held in a table (e.g. students, courses, books, instructors) and tables are related through a common field (a field that is in more than one table) microsoft access and corel paradox are both relational database management systems.\n",
      "\n",
      "result 3:\n",
      "score: 4.238364518320238\n",
      "entity:relational database\n",
      "definition id:28254\n",
      "definition:finite set of relations​. each relation consists of a schema and an instance​. database schema = set of relation schemas constraints among relations (inter-relational constraints)​. database instance = set of (corresponding) relation instances\n",
      "\n",
      "result 4:\n",
      "score: 4.122275123103649\n",
      "entity:relational model\n",
      "definition id:741\n",
      "definition:developed by ef codd of ibm in 19070, the relational model is based on mathematical set theory and represents data as independent relations. each relation (table) is conceptually represented as a two dimensional structure of intersecting rows and columns. the relations are related to each other through the sharing of common entity characteristics (values in columns). -to use an analogy, it produced an &\"automatic transmission&\" database to replace the &\"standard transmission&\" databases that preceded it. -describes a precise set of data manipulation constructs based on advanced mathematical concepts.\n",
      "\n",
      "result 5:\n",
      "score: 4.017820665941266\n",
      "entity:database management system\n",
      "definition id:654\n",
      "definition:dbms allows users to create, read, update, and delete structured data in a relational database. managers send requests to dbms and the dbms performs manipulation of the data. can retrieve information from using sql or qbe (query by example).   relational database management system: allows users to create, read, update, and delete data in a relational database.  pros: increased flexibility, inc scalability and performance, reduced info redundancy, inc info integrity/quality, increased info security.\n",
      "\n",
      "None\n",
      "query:garbage collection\n",
      "result 1:\n",
      "score: 7.185876112272187\n",
      "entity:garbage collection\n",
      "definition id:21553\n",
      "definition:garbage collection (gc) is a form of automatic memory management. the garbage collector, or just collector, attempts to reclaim garbage, or memory occupied by objects that are no longer in use by the program.\n",
      "\n",
      "result 2:\n",
      "score: 6.3292301409376925\n",
      "entity:garbage collection\n",
      "definition id:21554\n",
      "definition:there is a third phase of 2pc called garbage collection. replicas must retain records of past transactions, just in case leader fails. in practice, leader periodically tells replicas to garbage collect.\n",
      "\n",
      "result 3:\n",
      "score: 6.3292301409376925\n",
      "entity:garbage collection\n",
      "definition id:21550\n",
      "definition:automatic memory management is made possible by garbage collection in .net framework. when a class object is created at runtime, certain memory space is allocated to it in the heap memory. however, after all the actions related to the object are completed in the program, the memory space allocated to it is a waste as it cannot be used. in this case, garbage collection is very useful as it automatically releases the memory space after it is no longer required.\n",
      "\n",
      "result 4:\n",
      "score: 5.520628775347339\n",
      "entity:garbage collection\n",
      "definition id:21559\n",
      "definition:garbage collection is a feature that automatically deletes unused memory that is no longer being referenced. you cannot force it but you can request it using system.gc() but you should never use that because it slows down your program heavily. once the system thinks an object it ready for collection, it will call finalize() on it which does final cleanup and prepares it do be collected\n",
      "\n",
      "result 5:\n",
      "score: 4.864784180250639\n",
      "entity:garbage collector\n",
      "definition id:4150\n",
      "definition:the part of the operating system that performs garbage collection.\n",
      "\n",
      "None\n",
      "query:retrieval model\n",
      "result 1:\n",
      "score: 4.292304706110251\n",
      "entity:data model\n",
      "definition id:6983\n",
      "definition:- a collection of concepts that can be used to describe the structure of a database - describes the structure - dbms is based on a data model   structure of data model:  - records - types - relationships - constraints - basic operations (specifying retrievals and updates)  types of data models: - high-level (conceptual i.e. er) - low level (physical i.e. xml) - implementation (representational) combines conceptual and physical i.e. relational model - nosql data models i.e. column, key-value, document stores\n",
      "\n",
      "result 2:\n",
      "score: 3.459702278551742\n",
      "entity:mathematical model\n",
      "definition id:14170\n",
      "definition:mathematical models are usually composed of relationships and variables. relationships can be described by operators, such as algebraic operators, functions, differential operators, etc. variables are abstractions of system parameters of interest, that can be quantified. several classification criteria can be used for mathematical models according to their structure: • linear vs. nonlinear: if all the operators in a mathematical model exhibit linearity, the resulting mathematical model is defined as linear. a model is considered to be nonlinear otherwise. the definition of linearity and nonlinearity is dependent on context, and linear models may have nonlinear expressions in them. for example, in a statistical linear model, it is assumed that a relationship is linear in the parameters, but it may be nonlinear in the predictor variables. similarly, a differential equation is said to be linear if it can be written with linear differential operators, but it can still have nonlinear expressions in it. in a mathematical programming model, if the objective functions and constraints are represented entirely by linear equations, then the model is regarded as a linear model. if one or more of the objective functions or constraints are represented with a nonlinear equation, then the model is known as a nonlinear model. nonlinearity, even in fairly simple systems, is often associated with phenomena such as chaos and irreversibility. although there are exceptions, nonlinear systems and models tend to be more difficult to study than linear ones. a common approach to nonlinear problems is linearization, but this can be problematic if one is trying to study aspects such as irreversibility, which are strongly tied to nonlinearity. • static vs. dynamic: a dynamic model accounts for time-dependent changes in the state of the system, while a static (or steady-state) model calculates the system in equilibrium, and thus is time-invariant. dynamic models typically are represented by differential equations. • explicit vs. implicit: if all of the input parameters of the overall model are known, and the output parameters can be calculated by a finite series of computations (known as linear programming, not to be confused with linearity as described above), the model is said to be explicit. but sometimes it is the output parameters which are known, and the corresponding inputs must be solved for by an iterative procedure, such as newton's 10 method (if the model is linear) or broyden's method (if non-linear). for example, a jet engine's physical properties such as turbine and nozzle throat areas can be explicitly calculated given a design thermodynamic cycle (air and fuel flow rates, pressures, and temperatures) at a specific flight condition and power setting, but the engine's operating cycles at other flight conditions and power settings cannot be explicitly calculated from the constant physical properties. • discrete vs. continuous: a discrete model treats objects as discrete, such as the particles in a molecular model or the states in a statistical model; while a continuous model represents the objects in a continuous manner, such as the velocity field of fluid in pipe flows, temperatures and stresses in a solid, and electric field that applies continuously over the entire model due to a point charge. • deterministic vs. probabilistic (stochastic): a deterministic model is one in which every set of variable states is uniquely determined by parameters in the model and by sets of previous states of these variables; therefore, a deterministic model always performs the same way for a given set of initial conditions. conversely, in a stochastic model—usually called a &\"statistical model&\"—randomness is present, and variable states are not described by unique values, but rather by probability distributions. • deductive, inductive, or floating: a deductive model is a logical structure based on a theory. an inductive model arises from empirical findings and generalization from them. the floating model rests on neither theory nor observation, but is merely the invocation of expected structure. application of mathematics in social sciences outside of economics has been criticized for unfounded models. application of catastrophe theory in science has been characterized as a floating model.\n",
      "\n",
      "result 3:\n",
      "score: 3.3370417172064877\n",
      "entity:query language\n",
      "definition id:9085\n",
      "definition:used to update and retrieve data that is stored in a data model\n",
      "\n",
      "result 4:\n",
      "score: 3.3370417172064877\n",
      "entity:data model\n",
      "definition id:7031\n",
      "definition:\\ structure of data model:  - records - types - relationships - constraints - basic operations (specifying retrievals and updates)\n",
      "\n",
      "result 5:\n",
      "score: 3.3370417172064877\n",
      "entity:online analytical processing\n",
      "definition id:19733\n",
      "definition:a set of tools that provide advanced data analysis for retrieving, processing, and modeling data from the data warehouse\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(returnvalPart3(result1,\"relational database\",document_file,document_entity))\n",
    "print(returnvalPart3(result2,\"garbage collection\",document_file,document_entity))\n",
    "print(returnvalPart3(result3,\"retrieval model\",document_file,document_entity))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseDefination(query):\n",
    "    tokens = RegexpTokenizer(r'\\w+')\n",
    "    query = tokens.tokenize(query.lower())\n",
    "    stm = PorterStemmer()\n",
    "    if remove_stopwords:\n",
    "        query = [w for w in query if not w in stop_words]\n",
    "    if use_stemming:\n",
    "        query = [stm.stem(word) for word in query]    \n",
    "    return query\n",
    "#print(parseDefination('relational database'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B: Ranking with vector space model with TF-IDF (15 points) \n",
    "\n",
    "**Cosine:** You should use cosine as your scoring function. \n",
    "\n",
    "**TFIDF:** For the document vectors, use the standard TF-IDF scores as introduced in A. For the query vector, use simple weights (the raw term frequency). For example:\n",
    "* query: troll $\\rightarrow$ (1)\n",
    "* query: troll trace $\\rightarrow$ (1, 1)\n",
    "\n",
    "**Output:**\n",
    "For each given query in Part 2, you should just rank the documents retrieved by your boolean search. You only need to output the top-5 documents plus the cosine score of each of these documents. Please use the following format to present your results:\n",
    "\n",
    "* query: relational database\n",
    "* result 1:\n",
    "* score: 0.1\n",
    "* entity: database management system\n",
    "* definition id: 656\n",
    "* definition: software system used to manage databases\n",
    "* result 2:\n",
    "* ......\n",
    "* query: garbage collection\n",
    "* ......\n",
    "* query: retrieval model\n",
    "* ......\n",
    "\n",
    "You can additionally assume that your queries will contain at most three words. Be sure to normalize your vectors as part of the cosine calculation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calidf(vocab1):\n",
    "    idf_matrix_vocab = {}\n",
    "    for v in vocab1:\n",
    "        #print(v)\n",
    "        dftval = len(inverted_index[v])  #1057\n",
    "        #print(dftval)\n",
    "        idfval = math.log10(total_document/dftval)\n",
    "        #print(idf)\n",
    "        idf_matrix_vocab[v] = idfval\n",
    "\n",
    "    return  idf_matrix_vocab\n",
    "\n",
    "#print(calidf(vocab1)['yellow'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'relat': 1.4661083113184445, 'databas': 1.2538980211778423}\n"
     ]
    }
   ],
   "source": [
    "def numerator(query):\n",
    "    query = parseDefination(query)  #['relat', 'databas']\n",
    "#print(query)\n",
    "\n",
    "    tfidf={}\n",
    "#numerator = tfid(relat) + tfid(database)\n",
    "\n",
    "    for docid in document_list:\n",
    "        for wrd in query:\n",
    "            if wrd not in inverted_index:\n",
    "                continue\n",
    "            word_frq = list(vocab1).count(wrd)\n",
    "            if(word_frq >0):\n",
    "                tfv = 1+ math.log10(word_frq)\n",
    "                #print(tfv)\n",
    "                idfv = idfmatrix[wrd]\n",
    "                #print(idfv)\n",
    "                tfidf[wrd] = tfv*idfv\n",
    "    return tfidf     \n",
    "\n",
    "print(numerator('relational database'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parseQuery(query):\n",
    "    query = parseDefination(query)\n",
    "    out ={}\n",
    "    for w in query:\n",
    "        word_frq = list(vocab1).count(w)\n",
    "        out[w] = word_frq\n",
    "    return out\n",
    "\n",
    "#print(parseQuery('relational database'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('831', 0.9969703954378698), ('28160', 0.6192489053674813), ('16052', 0.5614877243385036), ('7135', 0.5492173984278385), ('7008', 0.5464098806564088)]\n"
     ]
    }
   ],
   "source": [
    "def VSMCosine(query,outputBR):\n",
    "    queryvect = parseQuery(query)  #['relat', 'databas']\n",
    "    qdenm = 0\n",
    "    tfid = numerator(query)  #0': {'estim': 1, 'durat': 1, 'cost': 1, 'made': 1, 'compon': 1, 'separ': 1, 'combin': 1, 'provid': 1, 'overal': 1, 'figur': 1}\n",
    "    docvect=0\n",
    "    docdenm=0\n",
    "\n",
    "    ranking = []\n",
    "\n",
    "    sum=0\n",
    "    for i in tfid:     # according to query calculated\n",
    "        sum=sum+ tfid[i]\n",
    "\n",
    "#outputBR-- for relational database \n",
    "    for docid in outputBR:\n",
    "        for w in queryvect:\n",
    "            \n",
    "        #print(w)\n",
    "            qdenm = qdenm+(queryvect[w]*queryvect[w])\n",
    "            docdenm = docdenm +(tfid[w]*tfid[w])\n",
    "        qdenm = math.sqrt(qdenm) \n",
    "        docdenm = math.sqrt(docdenm)\n",
    "    \n",
    "    \n",
    "    \n",
    "        deno = qdenm*docdenm\n",
    "        nume = sum\n",
    "        cosine_score = nume/deno\n",
    "    \n",
    "        ranking.append((cosine_score,docid))\n",
    "        ranking = sorted(ranking, reverse = True)\n",
    "\n",
    "    cosine_score_list = [(ranked[1],ranked[0]) for ranked in ranking]\n",
    "    result_VSM  = cosine_score_list[:5]\n",
    "    return result_VSM\n",
    "\n",
    "print(VSMCosine('relational database',outputBR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultX = VSMCosine('relational database',outputBR)\n",
    "resultY = VSMCosine('garbage collection',outputBR2)\n",
    "resultZ = VSMCosine('retrieval model',outputBR3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:relational database\n",
      "result 1:\n",
      "score: 0.9969703954378698\n",
      "entity:relational model\n",
      "definition id:831\n",
      "definition:a database model that describes data in which all data elements are placed in two-dimensional tables, called relations, which are the logical equivalent of files.\n",
      "\n",
      "result 2:\n",
      "score: 0.6192489053674813\n",
      "entity:relational database\n",
      "definition id:28160\n",
      "definition:a group of related databases associated by a key, or a common identifying (qualitative) characteristic.\n",
      "\n",
      "result 3:\n",
      "score: 0.5614877243385036\n",
      "entity:data management\n",
      "definition id:16052\n",
      "definition:data stored in relational databases -tables stored in secondary storage\n",
      "\n",
      "result 4:\n",
      "score: 0.5492173984278385\n",
      "entity:relational algebra\n",
      "definition id:7135\n",
      "definition:a theoretical way of manipulating a relational database based on set theory\n",
      "\n",
      "result 5:\n",
      "score: 0.5464098806564088\n",
      "entity:data model\n",
      "definition id:7008\n",
      "definition:model used for planning the org's database that identifies what kind of info is needed, what entities will be created and how they are related to one another\n",
      "\n",
      "None\n",
      "query:garbage collection\n",
      "result 1:\n",
      "score: 0.9170356455131211\n",
      "entity:garbage collection\n",
      "definition id:21559\n",
      "definition:garbage collection is a feature that automatically deletes unused memory that is no longer being referenced. you cannot force it but you can request it using system.gc() but you should never use that because it slows down your program heavily. once the system thinks an object it ready for collection, it will call finalize() on it which does final cleanup and prepares it do be collected\n",
      "\n",
      "result 2:\n",
      "score: 0.6236461367567248\n",
      "entity:garbage collection\n",
      "definition id:21555\n",
      "definition:when data is no longer referable (i.e., there are no remaining references to that data available for executable code), it is &\"garbage collected&\" and will be destroyed at some later point in time\n",
      "\n",
      "result 3:\n",
      "score: 0.5798576471867491\n",
      "entity:garbage collection\n",
      "definition id:21576\n",
      "definition:a class instance is explicitly created by the java code and after use it is automatically destroyed by garbage collection for memory management.\n",
      "\n",
      "result 4:\n",
      "score: 0.5706048111186915\n",
      "entity:garbage collection\n",
      "definition id:21553\n",
      "definition:garbage collection (gc) is a form of automatic memory management. the garbage collector, or just collector, attempts to reclaim garbage, or memory occupied by objects that are no longer in use by the program.\n",
      "\n",
      "result 5:\n",
      "score: 0.5684418544368959\n",
      "entity:garbage collection\n",
      "definition id:21554\n",
      "definition:there is a third phase of 2pc called garbage collection. replicas must retain records of past transactions, just in case leader fails. in practice, leader periodically tells replicas to garbage collect.\n",
      "\n",
      "None\n",
      "query:retrieval model\n",
      "result 1:\n",
      "score: 0.9840269275532088\n",
      "entity:query language\n",
      "definition id:9085\n",
      "definition:used to update and retrieve data that is stored in a data model\n",
      "\n",
      "result 2:\n",
      "score: 0.6326850928931013\n",
      "entity:online analytical processing\n",
      "definition id:19727\n",
      "definition:tools for retrieving, processing, and modelling data from the data warehouse\n",
      "\n",
      "result 3:\n",
      "score: 0.5799501548050091\n",
      "entity:web browser\n",
      "definition id:17705\n",
      "definition:-a software application used to locate, retrieve, and display content on the world wide web, including web pages, images, video, and other files -as a client/server model, the browser is the client on a computer that contacts the web server and requests information. the web server sends the information back to the web brows\n",
      "\n",
      "result 4:\n",
      "score: 0.5689568617107394\n",
      "entity:physical design\n",
      "definition id:10327\n",
      "definition:translate logical model into technical specifications for storing/retrieving data, store data to achieve efficiency and quality\n",
      "\n",
      "result 5:\n",
      "score: 0.5664626511008432\n",
      "entity:physical design\n",
      "definition id:10341\n",
      "definition:-translate logical model into technical specification for strong/retrieving data -store data to achieve efficiency and quality\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(returnvalPart3(resultX,\"relational database\",document_file,document_entity))\n",
    "print(returnvalPart3(resultY,\"garbage collection\",document_file,document_entity))\n",
    "print(returnvalPart3(resultZ,\"retrieval model\",document_file,document_entity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C: Ranking with BM25 (20 points) \n",
    "Finally, let's try the BM25 approach for ranking. Refer to https://en.wikipedia.org/wiki/Okapi_BM25 for the specific formula. You could choose k_1 = 1.2 and b = 0.75 but feel free to try other options.\n",
    "\n",
    "**Output:**\n",
    "For each given query in Part 2, you should just rank the documents retrieved by your boolean search. You only need to output the top-5 documents plus the BM25 score of each of these documents. Please use the following format to present your results:\n",
    "\n",
    "* query: relational database\n",
    "* result 1:\n",
    "* score: 0.1\n",
    "* entity: database management system\n",
    "* definition id: 656\n",
    "* definition: software system used to manage databases\n",
    "* result 2:\n",
    "* ......\n",
    "* query: garbage collection\n",
    "* ......\n",
    "* query: retrieval model\n",
    "* ......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outputBR-- for relational database \n",
    "sum=0\n",
    "for docid in outputBR:\n",
    "    sum =sum + word_count[docid]\n",
    "\n",
    "avglen =float(sum) / float(len(outputBR))\n",
    "\n",
    "#print(avglen)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.14141087427629\n"
     ]
    }
   ],
   "source": [
    "#document_list ==== total document considered\n",
    "sum=0\n",
    "for docid in document_list:\n",
    "    sum =sum + word_count[docid]\n",
    "\n",
    "avglen_total =float(sum) / float(len(document_list))\n",
    "\n",
    "print(avglen_total)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimates of duration and cost are made for each component separately and combined to provide an overall figure\n",
      "\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "print(document_file[0])\n",
    "wds = document_file[0].split(\" \")\n",
    "print(len(wds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    }
   ],
   "source": [
    "word_count = {}\n",
    "for docid in document_list:\n",
    "    word_count[docid]= len(document_file[int(docid)].split(\" \"))\n",
    "#print (word_count)   \n",
    "k2=4\n",
    "print(word_count['0'])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = 1.5\n",
    "\n",
    "b = 0.75\n",
    "\n",
    "def scoreBM25(f,n,avgdl,queryTerm):\n",
    "    numerator = f*(k1+1)*k2\n",
    "    deno1 = (n/avgdl)*b\n",
    "    denominator = f + k1*(1-b + deno1)\n",
    "    sm = (numerator/denominator)*idfmax[queryTerm]\n",
    "    return sm\n",
    "\n",
    "score = scoreBM25(word_freq,n,avglen_total,'relat')\n",
    "#print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BM25(query,outputBR):\n",
    "    queryvect = parseQuery(query)  # {'relat': 1, 'databas': 1}\n",
    "\n",
    "    ranks = []\n",
    "\n",
    "#outputBR-- for relational database \n",
    "    for docid in outputBR:\n",
    "        for w in queryvect:\n",
    "            if w not in inverted_index:\n",
    "                    continue\n",
    "            parsedDocument = document_file[int(docid)]\n",
    "            #print(parsedDocument)\n",
    "            word_freq = parsedDocument.count(w)\n",
    "            #print(word_freq)\n",
    "            if(word_freq >0):\n",
    "                wds = parsedDocument.split(\" \")\n",
    "                n = len(parsedDocument) \n",
    "                #print(n)#no of words in parsed document\n",
    "                score = scoreBM25(word_freq,n,avglen_total,w)\n",
    "    \n",
    "        ranks.append((score,docid))\n",
    "        ranks = sorted(ranks, reverse = True)\n",
    "\n",
    "    BM25_list = [(ranked[1],ranked[0]) for ranked in ranks]\n",
    "    return BM25_list[:5]\n",
    "\n",
    "#print(BM25('relational database',outputBR))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultA = BM25('relational database',outputBR)\n",
    "resultB = BM25('garbage collection',outputBR2)\n",
    "resultC = BM25('retrieval model',outputBR3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:relational database\n",
      "result 1:\n",
      "score: 4.70036763058626\n",
      "entity:relational database\n",
      "definition id:28205\n",
      "definition:a database built using the relational database model\n",
      "\n",
      "result 2:\n",
      "score: 3.701653166778901\n",
      "entity:relational databases\n",
      "definition id:5134\n",
      "definition:• a database is intended to be shared by many users • there are three structures for storing database files: - relational database structures - hierarchical database structures - network database structures\n",
      "\n",
      "result 3:\n",
      "score: 3.6433178422136003\n",
      "entity:relational database\n",
      "definition id:28177\n",
      "definition:relational database schema with data\n",
      "\n",
      "result 4:\n",
      "score: 3.4741687611343863\n",
      "entity:relational database\n",
      "definition id:28210\n",
      "definition:a collection of related database tables\n",
      "\n",
      "result 5:\n",
      "score: 3.2716443379401814\n",
      "entity:relational database\n",
      "definition id:28227\n",
      "definition:a database using the relational data model.\n",
      "\n",
      "None\n",
      "query:garbage collection\n",
      "result 1:\n",
      "score: 2.740246983633277\n",
      "entity:garbage collection\n",
      "definition id:21553\n",
      "definition:garbage collection (gc) is a form of automatic memory management. the garbage collector, or just collector, attempts to reclaim garbage, or memory occupied by objects that are no longer in use by the program.\n",
      "\n",
      "result 2:\n",
      "score: 2.6861342500210723\n",
      "entity:garbage collector\n",
      "definition id:4150\n",
      "definition:the part of the operating system that performs garbage collection.\n",
      "\n",
      "result 3:\n",
      "score: 2.0046884614240383\n",
      "entity:garbage collection\n",
      "definition id:21554\n",
      "definition:there is a third phase of 2pc called garbage collection. replicas must retain records of past transactions, just in case leader fails. in practice, leader periodically tells replicas to garbage collect.\n",
      "\n",
      "result 4:\n",
      "score: 1.7753653344158555\n",
      "entity:memory safety\n",
      "definition id:13115\n",
      "definition:memory management handled differently such that there is garbage collection, prevent dangling pointer references.\n",
      "\n",
      "result 5:\n",
      "score: 1.642743953644379\n",
      "entity:garbage collection\n",
      "definition id:21559\n",
      "definition:garbage collection is a feature that automatically deletes unused memory that is no longer being referenced. you cannot force it but you can request it using system.gc() but you should never use that because it slows down your program heavily. once the system thinks an object it ready for collection, it will call finalize() on it which does final cleanup and prepares it do be collected\n",
      "\n",
      "None\n",
      "query:retrieval model\n",
      "result 1:\n",
      "score: 2.76107942573534\n",
      "entity:query language\n",
      "definition id:9085\n",
      "definition:used to update and retrieve data that is stored in a data model\n",
      "\n",
      "result 2:\n",
      "score: 2.506516761804835\n",
      "entity:online analytical processing\n",
      "definition id:19731\n",
      "definition:enable retrieving, processing, and modeling data from the data warehouse\n",
      "\n",
      "result 3:\n",
      "score: 2.407851780303483\n",
      "entity:online analytical processing\n",
      "definition id:19727\n",
      "definition:tools for retrieving, processing, and modelling data from the data warehouse\n",
      "\n",
      "result 4:\n",
      "score: 2.273606511443936\n",
      "entity:online analytical processing\n",
      "definition id:19708\n",
      "definition:olap - tools for retrieving, processing, and modeling data from the data warehouse\n",
      "\n",
      "result 5:\n",
      "score: 2.0080993419549764\n",
      "entity:data model\n",
      "definition id:6983\n",
      "definition:- a collection of concepts that can be used to describe the structure of a database - describes the structure - dbms is based on a data model   structure of data model:  - records - types - relationships - constraints - basic operations (specifying retrievals and updates)  types of data models: - high-level (conceptual i.e. er) - low level (physical i.e. xml) - implementation (representational) combines conceptual and physical i.e. relational model - nosql data models i.e. column, key-value, document stores\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(returnvalPart3(resultA,\"relational database\",document_file,document_entity))\n",
    "print(returnvalPart3(resultB,\"garbage collection\",document_file,document_entity))\n",
    "print(returnvalPart3(resultC,\"retrieval model\",document_file,document_entity))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussio\n",
    "Briefly discuss the differences you see between the three methods. Is there one you prefer?\n",
    "\n",
    "## BONUS --EVALUATION(10 POINTS)\n",
    "Rather than just compare methods by pure observation, there are several metrics to evaluate the performance of an IR engine: Precision, Recall, MAP, NDCG, HitRate and so on. These all require a ground truth set of queries and documents with a notion of relevance. These ground truth judgments can be expensive to obtain, so we are cutting corners here and treating a flashcard's front and back as a \"relevant\" query-document pair.\n",
    "\n",
    "That is, if a document (definition) in your top-5 results is from the back of query's (entity's) flashcard, this document is regarded as relevant to the query (entity). This document is also called a hit in IR. Based on the ground-truth, you could calculate the metrics for the three ranking methods and provide the results like these:\n",
    "\n",
    "metric: Precision@5\n",
    "TF-IDF - score1\n",
    "Vector Space Model with TF-IDF - score2\n",
    "BM25 - score3\n",
    "You could pick any of the reasonable metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:relational database\n",
      "precision for TFID =  0.4\n",
      "query:relational database\n",
      "precision for VSM =  0.2\n",
      "query:relational database\n",
      "precision for BM25 =  0.26666666666666666\n"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "#BM25\n",
    "def Precision(output,query,document_file,document_entity):\n",
    "    print(\"query:\" + query)\n",
    "    count =0\n",
    "    for num in range(len(output)):\n",
    "        \n",
    "        if(isinstance(output[0],tuple)):\n",
    "            id = output[num][0]\n",
    "            score = str(output[num][1])\n",
    "            entity= document_entity[int(id)]\n",
    "            docid=  str(id)\n",
    "            definition = document_file[int(id)]\n",
    "            if(entity==query):\n",
    "                count=count+1\n",
    "    return count     \n",
    "num1 =Precision(result1,\"relational database\",document_file,document_entity)\n",
    "print(\"precision for TFID = \" , num1/5)\n",
    "num2 =Precision(resultX,\"relational database\",document_file,document_entity)\n",
    "print(\"precision for VSM = \" , num2/5)\n",
    "num3 =Precision(resultA,\"relational database\",document_file,document_entity)\n",
    "print(\"precision for BM25 = \" , num3/15) #FOR ALL CALS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collaboration Declarations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** You should fill out your collaboration declarations here.**\n",
    "\n",
    "**Reminder:** You are expected to complete each homework independently. Your solution should be written by you without the direct aid or help of anyone else. However, we believe that collaboration and team work are important for facilitating learning, so we encourage you to discuss problems and general problem approaches (but not actual solutions) with your classmates. You may post on Piazza, search StackOverflow, etc. But if you do get help in this way, you must inform us by filling out the Collaboration Declarations at the bottom of this notebook.\n",
    "\n",
    "Example: I found helpful code on stackoverflow at https://stackoverflow.com/questions/11764539/writing-fizzbuzz that helped me solve Problem 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
